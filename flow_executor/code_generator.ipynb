{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from coai_datasets.dataset_manager import DatasetManager\n",
      "from coai_datasets.standard.mlsum_dataset import MLSUMDataset\n",
      "from coai_datasets.standard.mmlu_dataset import MMLUDataset\n",
      "from config.config import Config\n",
      "from evaluation.metrics import BLEUMetric, Rouge1Metric\n",
      "from evaluation.MMLUEvaluationFramework import MMLUFramework\n",
      "from evaluation.SUMEvalFramework import SUMEvalFramework\n",
      "from evaluation.MTBenchEvaluationFramework import MTBenchEvaluationFramework\n",
      "from exporter.EvalExporter import EvalExporter\n",
      "from models.openai_model import OpenAIModel\n",
      "Config.set_user_id('github|149702207')\n",
      "Config.set_project_id('5cc73596-ad33-4659-afbd-b1972826e79b')\n",
      "Config.set_tracing_key('dummy')\n",
      "c6ab1f7378ed4d62a3dce1bd5ed61fa0 = MLSUMDataset()\n",
      "c6ab1f7378ed4d62a3dce1bd5ed61fa0.load(nb_items=2)\n",
      "f20527638ea94753b9c6f17232fc7c9b = COAIDataset()\n",
      "f20527638ea94753b9c6f17232fc7c9b.load(dataset_id='331d506e-d7d0-40e9-b2e0-2a67d626af84')\n",
      "80d67ff67c1d412c8cd6b2eefeea3128 = SUMEvalFramework(device='cuda')\n",
      "17361a9342b54ff1bfea2aee53146129 = SUMEvalFramework(device='cuda')\n",
      "d461d7aecd9b4ed9a46d5907dc3caefb = EvalExporter(title='exporter_title')\n",
      "eval_80d67ff67c1d412c8cd6b2eefeea3128 = 80d67ff67c1d412c8cd6b2eefeea3128.evaluate(model=dummy, dataset=c6ab1f7378ed4d62a3dce1bd5ed61fa0.data, eval_name=d461d7aecd9b4ed9a46d5907dc3caefb.title)\n",
      "d461d7aecd9b4ed9a46d5907dc3caefb.add_eval(eval_80d67ff67c1d412c8cd6b2eefeea3128)\n",
      "d461d7aecd9b4ed9a46d5907dc3caefb.export()\n",
      "eval_17361a9342b54ff1bfea2aee53146129 = 17361a9342b54ff1bfea2aee53146129.evaluate(model=dummy, dataset=f20527638ea94753b9c6f17232fc7c9b.data, eval_name=d461d7aecd9b4ed9a46d5907dc3caefb.title)\n",
      "d461d7aecd9b4ed9a46d5907dc3caefb.add_eval(eval_17361a9342b54ff1bfea2aee53146129)\n",
      "d461d7aecd9b4ed9a46d5907dc3caefb.export()\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from typing import Dict, List, Any\n",
    "from component_mapping import COMPONENT_MAPPING\n",
    "from demo_definition import FLOW_DEFINITION\n",
    "from pprint import pprint\n",
    "\n",
    "BASE_IMPORTS_FOR_CODE = [\n",
    "\"from coai_datasets.dataset_manager import DatasetManager\",\n",
    "\"from coai_datasets.standard import *\",\n",
    "\"from config.config import Config\",\n",
    "\"from evaluation.metrics import BLEUMetric, Rouge1Metric\",\n",
    "\"from evaluation import *\",\n",
    "\"from exporter.EvalExporter import EvalExporter\",\n",
    "\"from models.openai_model import OpenAIModel\"\n",
    "]\n",
    "\n",
    "def run_format(line, variables):\n",
    "    try: \n",
    "        #for debugging, remove the comments for the print statements\n",
    "        valid_variables = {k: v for k, v in variables.items() if k in line}\n",
    "        #print(f\"attempting to format line: \\n{line} \\nwith variables: \\n{valid_variables}\")\n",
    "        line = line.format_map(valid_variables)\n",
    "        #print(f\"final result: \")\n",
    "        #print(f\"{line}\")\n",
    "        #print(\"\\n\")\n",
    "        return line\n",
    "    except KeyError as e:\n",
    "        return \n",
    "\n",
    "def group_edges(edges):\n",
    "    # Create an empty dictionary to hold grouped data\n",
    "    grouped_data = {} \n",
    "    #Group the edges by their target component and add the relevant variable names for model, exporter, dataset, framework\n",
    "    for item in edges:\n",
    "        target = item[\"target\"].replace('-','')\n",
    "        \n",
    "        item[\"target\"] = item[\"target\"].replace('-','')\n",
    "        item[\"source\"] = item[\"source\"].replace('-','')   \n",
    "        if \"dataset\" in item[\"sourceHandle\"]:\n",
    "            item[\"dataset\"] = item[\"source\"]\n",
    "        if \"model\" in item[\"sourceHandle\"]:\n",
    "            item[\"model\"] = item[\"source\"]    \n",
    "        if \"exporter\" in item[\"targetHandle\"]:\n",
    "            item[\"exporter\"] = item[\"target\"]\n",
    "            dataset_reference_edges = grouped_data[item[\"source\"]]\n",
    "            for dataset_item in dataset_reference_edges:\n",
    "                item[\"dataset\"] = dataset_item[\"dataset\"]\n",
    "        if \"framework\" in item[\"sourceHandle\"]:\n",
    "            item[\"framework\"] = item[\"source\"]\n",
    "        #dummy for now:\n",
    "        item[\"model\"]=\"dummy\"\n",
    "        if target not in grouped_data:\n",
    "            grouped_data[target] = []\n",
    "        grouped_data[target].append(item)\n",
    "    return grouped_data\n",
    "\n",
    "\n",
    "def generate_python_script(components: Dict[Any,Any]):\n",
    "    script_lines = BASE_IMPORTS_FOR_CODE\n",
    "    config_values = {}\n",
    "    for component in components[\"nodes\"]:\n",
    "        # store the id of the current component since this gets overridden to a non unique id if the following condition is true\n",
    "        variable_name = component[\"id\"].replace('-','')\n",
    "        config_values[variable_name] = {}\n",
    "        # if multiple instances of the same flow component exist, the actual definition is in the data key (this now means that the id of the component is no longer unique which is why it was stored before doing this)\n",
    "        if \"data\" in component.keys():\n",
    "            component = component[\"data\"]\n",
    "        mapping = COMPONENT_MAPPING[component[\"id\"]]\n",
    "        \n",
    "        if \"fields\" in component.keys():\n",
    "            #populate the field values for each variable and put them in a dict of pattern field_name:field_value\n",
    "            for field in component[\"fields\"]:\n",
    "                field_name = field[\"name\"]\n",
    "                field_value = field[\"value\"]\n",
    "                config_values[f\"{variable_name}\"][field_name]=field_value\n",
    "        if \"creation_lines\" in mapping.keys():\n",
    "            #create the instances of every component in the flow with its respective field values and variable names stored in the config_values dict\n",
    "            for line in mapping[\"creation_lines\"]:\n",
    "                if mapping.get(\"instance\"):\n",
    "                    config_values[variable_name][\"id\"]=variable_name\n",
    "                line = run_format(line, config_values[variable_name])\n",
    "                script_lines.append(line)\n",
    "    #group the edges by target so that for every target component you get all the inputs in one dict instead of having it spread out makes further processing easier\n",
    "    edges_dict = group_edges(components[\"edges\"])\n",
    "    #pprint(edges_dict)\n",
    "    for component in components[\"nodes\"]:\n",
    "        #some components get exported with their component id (if it is an exporter, mlsumdataset, config etc.) in data.id and some have them just in id even though id needs to be the unique id \n",
    "        if \"data\" in component.keys():\n",
    "            mapping = COMPONENT_MAPPING[component[\"data\"][\"id\"]]\n",
    "        else:\n",
    "            mapping = COMPONENT_MAPPING[component[\"id\"]]\n",
    "        \n",
    "        if \"execution_lines\" in mapping.keys():\n",
    "            for variable, edges in edges_dict.items():\n",
    "                for edge in edges:\n",
    "                    #keep count of how many lines are actually added for execution. preparation to not include wrongly generated lines\n",
    "                    count = 0\n",
    "                    temp_lines = []\n",
    "                    for line in mapping.get(\"execution_lines\"):\n",
    "                        config_values[variable].update(edge)\n",
    "                        line = run_format(line, config_values[variable])\n",
    "                        # every variables edges get computed even though they are not actually exporter variables. only two lines get returned by non exporter variables that should not be generated, thus just keeping count works\n",
    "                        if line:\n",
    "                            count += 1\n",
    "                            temp_lines.append(line)\n",
    "                            if count > 2:\n",
    "                                for temp_line in temp_lines:\n",
    "                                    script_lines.append(temp_line)\n",
    "    \n",
    "    return \"\\n\".join(script_lines)\n",
    "\n",
    "print(generate_python_script(components=FLOW_DEFINITION))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "      {\n",
    "        \"source\": \"75b51ac4-ecac-48ea-ad8b-5c43e93350cf\",\n",
    "        \"sourceHandle\": \"output-mlsum_dataset-0\",\n",
    "        \"target\": \"58c9b4f3-8536-4a23-8ecf-affbc26bd4a8\",\n",
    "        \"targetHandle\": \"input-sum_eval_framework-1\",\n",
    "        \"id\": \"reactflow__edge-75b51ac4-ecac-48ea-ad8b-5c43e93350cfoutput-mlsum_dataset-0-58c9b4f3-8536-4a23-8ecf-affbc26bd4a8input-sum_eval_framework-1\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"8773cbd6-f85b-4749-8539-e230592dd987\",\n",
    "        \"sourceHandle\": \"output-custom_dataset-0\",\n",
    "        \"target\": \"ada41bce-dfa6-43e3-8035-c89b3bb4dbdb\",\n",
    "        \"targetHandle\": \"input-sum_eval_framework-1\",\n",
    "        \"id\": \"reactflow__edge-8773cbd6-f85b-4749-8539-e230592dd987output-custom_dataset-0-ada41bce-dfa6-43e3-8035-c89b3bb4dbdbinput-sum_eval_framework-1\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"ada41bce-dfa6-43e3-8035-c89b3bb4dbdb\",\n",
    "        \"sourceHandle\": \"output-sum_eval_framework-0\",\n",
    "        \"target\": \"8bdc917c-bc19-414b-86cc-0cd612bca657\",\n",
    "        \"targetHandle\": \"input-eval_exporter-0\",\n",
    "        \"id\": \"reactflow__edge-ada41bce-dfa6-43e3-8035-c89b3bb4dbdboutput-sum_eval_framework-0-8bdc917c-bc19-414b-86cc-0cd612bca657input-eval_exporter-0\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"58c9b4f3-8536-4a23-8ecf-affbc26bd4a8\",\n",
    "        \"sourceHandle\": \"output-sum_eval_framework-0\",\n",
    "        \"target\": \"8bdc917c-bc19-414b-86cc-0cd612bca657\",\n",
    "        \"targetHandle\": \"input-eval_exporter-0\",\n",
    "        \"id\": \"reactflow__edge-58c9b4f3-8536-4a23-8ecf-affbc26bd4a8output-sum_eval_framework-0-8bdc917c-bc19-414b-86cc-0cd612bca657input-eval_exporter-0\"\n",
    "      }\n",
    "    ]\n",
    "\n",
    "# Create an empty dictionary to hold grouped data\n",
    "grouped_data = {}\n",
    "\n",
    "# Iterate through the data and group by \"target\"\n",
    "for item in edges:\n",
    "    target = item[\"target\"]\n",
    "    if target not in grouped_data:\n",
    "        grouped_data[target] = []\n",
    "    grouped_data[target].append(item)\n",
    "\n",
    "pprint(grouped_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monitoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
