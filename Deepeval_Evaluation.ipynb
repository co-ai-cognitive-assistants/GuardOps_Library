{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81325e1af0654c58aa61eb033c16e83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test cases...\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b314b770275418d9796f6a5933a5321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/windows/miniconda3/envs/monitoring/lib/python3.10/site-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4-turbo-preview, reason: The score is 1.00 because the response directly addresses the concern about the shoes fitting, and there are no irrelevant statements in the output., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: We offer a 30-day full refund at no extra costs.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra costs.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4-turbo-preview, reason: The score is 1.00 because there were no irrelevant statements made in the actual output, ensuring that the response was entirely focused on addressing whether the shoes would fit or not., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: We offer a 30-day full refund at no extra costs.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra costs.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "AnswerRelevancyMetric: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/windows/miniconda3/envs/monitoring/lib/python3.10/site-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models import GPTModel\n",
    "from evaluation.DeepevalFramework import DeepevalFramework\n",
    "from config.config import Config\n",
    "\n",
    "#Set up the coai parameters in the config\n",
    "Config.set_user_id(\"placeholder\")\n",
    "Config.set_project_id(\"placeholder\")\n",
    "\n",
    "\n",
    "# Set up deepeval as usual (example from docs used here)\n",
    "answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7,model=GPTModel(model=\"gpt-4-turbo-preview\",api_key=\"test\"))\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    # Replace this with the actual output from your LLM application\n",
    "    actual_output=\"We offer a 30-day full refund at no extra costs.\",\n",
    "    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n",
    ")\n",
    "test_case2 = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    # Replace this with the actual output from your LLM application\n",
    "    actual_output=\"We offer a 30-day full refund at no extra costs.\",\n",
    "    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n",
    ")\n",
    "\n",
    "#Use the wrapper for coai\n",
    "\n",
    "eval_framework = DeepevalFramework()\n",
    "evaluation = eval_framework.evaluate(eval_name=\"Deepeval\",test_cases=[test_case,test_case2] , metrics= [answer_relevancy_metric])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with ID 55c327a8-f973-4628-9148-2a163e53dfd5 stored in EvalExporter\n",
      "Successfully exported 55c327a8-f973-4628-9148-2a163e53dfd5 - Deepeval\n",
      "Successfully exported 1 evaluations.\n"
     ]
    }
   ],
   "source": [
    "# Export it \n",
    "from exporter.EvalExporter import EvalExporter\n",
    "exporter = EvalExporter(title=\"Deepeval Wrapper\")\n",
    "exporter.add_eval(eval = evaluation)\n",
    "exporter.export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monitoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
